{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778294c1-b55b-4eb2-afac-a3e377d005ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_google_vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f1d49-9d4d-4f52-b227-93d936391f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87901ff6-90ec-47fc-8391-7657983eecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d853a8e-5b1e-4e31-bab6-bf28cba5967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77e5f1-6a98-40f8-8897-e62cd93af415",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install json-repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59dd3c-1bb9-46c4-8fcc-a6d6a0728e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf43c3-a413-4f25-90a1-311c7b1c24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-cypher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b3387-28f5-477c-8405-e968110871fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc8da30-68fc-4ed6-b888-1d736cf1e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453b368-824c-4384-a024-6c154f2b1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cypher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b83d1-9862-4c9e-a65c-b0fb317361e6",
   "metadata": {},
   "source": [
    "## Neo4j Advanced rag \n",
    "https://github.com/langchain-ai/langchain/tree/master/templates/neo4j-advanced-rag this is has open ai reference and below you can find the gcp model implementation\n",
    "\n",
    "Future work\n",
    "\n",
    "Comparitive study with https://python.langchain.com/v0.1/docs/use_cases/graph/constructing/ approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39416959-a4c4-420a-bc5c-ec176669cc22",
   "metadata": {},
   "source": [
    "![Architecture](./Architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1672176-b9cf-4ee3-88dd-20fd38e60bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "from langchain_google_vertexai import (\n",
    "    VertexAI,\n",
    "    ChatVertexAI,\n",
    "    VertexAIEmbeddings,\n",
    "    VectorSearchVectorStore,\n",
    ")\n",
    "from google.cloud import aiplatform\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from neo4j.exceptions import ClientError\n",
    "import os\n",
    "from vertexai.generative_models import GenerativeModel, Image\n",
    "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
    "from langchain_google_vertexai import ChatVertexAI, HarmBlockThreshold, HarmCategory\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from typing import List, Tuple\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField, RunnableParallel,RunnableLambda\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import base64\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "import typing\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7cc935-e7fe-4146-9a7c-5daca7d6121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"bolt://10.113.8.4:8085\"\n",
    "username =\"neo4j\"\n",
    "password = \"password\"\n",
    "os.environ[\"NEO4J_URI\"] = url\n",
    "os.environ[\"NEO4J_USERNAME\"] = username\n",
    "os.environ[\"NEO4J_PASSWORD\"] = password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7ca925-a023-422d-9d5b-8239c959e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"edl-idaas-rnd-platform-d5ae\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b4e866-4e50-4842-89ad-f2a41533f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH (n) MATCH ()-[r]->() RETURN n, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19f6c6c-d83c-47ea-be81-8742a31fa694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH (n) OPTIONAL MATCH (n)-[r]-() DELETE n, r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2bae52-e73c-462a-a5c6-de3dcfd142ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path = \"/home/sridhanya_ganapathi_team_neustar/rag/data/images\"\n",
    "pdf_file_name = \"/home/sridhanya_ganapathi_team_neustar/rag/data/contract_agreement.pdf\"\n",
    "Pdf_title=\"contract_agreement.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be289937-764a-4193-971c-ad25e591ba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "image_pdf_folder_path = \"/home/sridhanya_ganapathi_team_neustar/rag/data/images\"\n",
    "pdf_file_name = \"/home/sridhanya_ganapathi_team_neustar/rag/data/contract_agreement.pdf\"\n",
    "\n",
    "# Extract images, tables, and chunk text from a PDF file.\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=pdf_file_name,\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=pdf_folder_path,\n",
    "    extract_image_block_types=[\"Image\", \"Table\"],\n",
    "    extract_image_block_output_dir=image_pdf_folder_path,\n",
    "    extract_image_block_to_payload=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5b49d5-8f8c-4afa-9f7b-dacf064a88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Categorize extracted elements from a PDF into tables and texts.\n",
    "tables = []\n",
    "texts = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        tables.append(str(element))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        texts.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac7323a5-e86f-4c2f-95c4-f4c76e6246c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8553a45-9506-4f04-afc1-f823546fc926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ni iE P.O. Box 1749 Halifax, Nova Scotia REGIONAL MUNICIPALITY B3J 3A5 Canada\\n\\nHalifax Regional Council August 6, 2013\\n\\nItem No. 14.1\\n\\nTO:         Mayor Savage and Members of Halifax Regional Council                  SUBMITTED BY:  ___________________________________________________________                                       Richard Butts, Chief Administrative Officer         __________________________________________________________  Mike Labrecque, Deputy Chief Administrative Officer      DATE:      July 31, 2013      SUBJECT:   Non-Disclosure Agreement with the Province of Nova Scotia   \\n\\n  \\n\\n     \\n\\nORIGIN\\n\\nOn June 25, 2013, Regional Council authorized the CAO to negotiate and execute an agreement for SAP support services with the Province of Nova Scotia.\\n\\nLEGISLATIVE AUTHORITY\\n\\nUnder section 58(5) of the HRM Charter, Regional Council has the power to make and carry out a contract. Under section 10(3) of the HRM Charter, the Mayor and Clerk may sign any document to which the Municipality is a party on behalf of the Municipality.\\n\\nRECOMMENDATION\\n\\nIt is recommended that Regional Council authorize the Mayor and Clerk to sign a Non- Disclosure Agreement with the Province of Nova Scotia with terms and conditions substantially similar to the draft agreement attached hereto as Attachment “A”.\\n\\nNon-Disclosure Agreement with the Province of NS - 2 - Council Report\\n\\nAugust 6, 2013\\n\\nBACKGROUND\\n\\nIn furtherance of the June 25, 2013 directive of Regional Council, staff entered into negotiations with the Province of Nova Scotia (“PNS”) on those terms and conditions that were not already agreed to during transition planning.\\n\\nDISCUSSION\\n\\nIt became apparent during these negotiations that HRM staff needed to be made aware of certain key terms of the PNS’ agreement with its SAP service provider in order to understand and be in a position to negotiate for appropriate service level standards. The PNS has taken the position that it cannot disclose this and other information to HRM unless HRM and the PNS enter into a mutual Non-Disclosure Agreement.\\n\\nOn July 26, 2013, the PNS forwarded a proposed Non-Disclosure Agreement to staff. This Non- Disclosure Agreement permits the PNS and HRM to disclose confidential information to each other during the period of negotiations. Any confidential information exchanged between HRM and the PNS “shall only be used for the purposes of facilitating the business relationship between the Parties” and once the agreement terminates each party must “promptly return or destroy” all confidential information received from the other party.\\n\\nIt is the intention of HRM and the PNS to execute an agreement for the provision of SAP support services before September 9, 2013. As a result, staff is seeking direction on this matter from Regional Council on August 6, 2013, rather than waiting for the next scheduled meeting of Regional Council on September 10, 2013.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2515496b-f2b0-482c-8a4b-cfb374632a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Enforce a specific token size for texts\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=5000, chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0026f6b9-1365-4179-9fcb-2e0b4b45b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings & LLM models\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embedding_dimension = 768\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Loading Gemini Pro Vision Model\n",
    "multimodal_model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "# Initializing embedding model\n",
    "EMBEDDING_MODEL =VertexAIEmbeddings(model_name=\"textembedding-gecko@003\", dimension=768) #TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")\n",
    "\n",
    "# Loading Gemini Pro Model\n",
    "llm = ChatVertexAI(\n",
    "    model_name=\"gemini-1.5-pro-001\",\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
    "    },\n",
    ")\n",
    "\n",
    "ollamallm = ChatOllama(base_url='http://10.113.8.4:8086',\n",
    "    model=\"llama3:latest\", temperature=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63aeb73-dea6-4253-b41e-233ecf38593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_transformer = LLMGraphTransformer(llm=llm,\n",
    "#                                       allowed_nodes=[\"Person\", \"Country\", \"Organization\", \"Location\", \"Legal Authority\",\"Effective Date\", \"Signed Date\"],\n",
    "#                                       allowed_relationships=[\"signed by\", \"Signed on\", \"Section\", \"Report Prepared by\", 'Report Signed by', 'Originally signed', 'Submitted by'],\n",
    "#                                       strict_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96774a9a-1d66-4779-a409-7e79053793fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_transformer = LLMGraphTransformer(llm=llm,     allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "#     allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],strict_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169a32c1-0611-4889-a1ff-2f667beb0020",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=ollamallm, allowed_nodes=[\"Person\", \"Country\", \"Organization\", \"Location\", \"Effective Date\", \"Signed Date\", \"heading\"],\n",
    "                                      allowed_relationships=[\"signed by\", \"Signed on\", \"Section\"],\n",
    "                                  strict_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "580d7edb-448a-4363-9df6-35e59e97256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = text_splitter.create_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0146b9d7-ea88-45a3-89c7-702080071c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    graph1 = llm_transformer.convert_to_graph_documents(doc1)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing document: {e}\") \n",
    "# # Output the graph for inspection\n",
    "\n",
    "# print(graph1)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5912618-e7b5-43cd-9e5d-3574df39df69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f825ce-7115-4a92-b477-e95c0ebe50de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948a8e1-5230-4421-9a54-2e65ec568a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b5b6e-9d67-468f-b9e7-1470ffe7f1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2cf093-8e95-4b9a-9590-b8f286278cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6a237f4-84fd-4b3c-9c27-9aea0e9e0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Richard Butts, Chief Administrative Officer', type='Person'), Node(id='Halifax Regional Council', type='Organization'), Node(id='Mayor Savage and Members of Halifax Regional Council', type='Organization'), Node(id='Mike Labrecque, Deputy Chief Administrative Officer', type='Person'), Node(id='Non-Disclosure Agreement with the Province of Nova Scotia', type='Agreement')]\n",
      "Relationships:[Relationship(source=Node(id='David Greener', type='Person'), target=Node(id='Legal Services', type='Organization'), type='PREPARED_BY'), Relationship(source=Node(id='Martin Ward, Q.C.', type='Person'), target=Node(id='Legal Services', type='Organization'), type='ACTING_DIRECTOR'), Relationship(source=Node(id='Halifax Regional Municipality', type='Organization'), target=Node(id='Her Majesty the Queen in right of the Province of Nova Scotia', type='Government'), type='PARTY_TO')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nodes:{graph1[0].nodes}\")\n",
    "print(f\"Relationships:{graph1[1].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d59caed-d42d-407d-abb8-89187adf43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngraph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e99e01c7-c956-490c-86f2-b0d7e6e73d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18e28390-7dea-4f6c-a3c0-9cd92aed10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngraph.add_graph_documents(graph1,\n",
    "                    baseEntityLabel=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f4fd0c8-66b3-43ab-b63b-9d578bb58fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gemini-1.5-pro-001\"\n",
    "\n",
    "\n",
    "# Generate summaries of text elements\n",
    "def generate_text_summaries(\n",
    "    texts: List[str], tables: List[str], summarize_texts: bool = False\n",
    ") -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Give a elaborate concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_text)\n",
    "    empty_response = RunnableLambda(\n",
    "        lambda x: AIMessage(content=\"Error processing document\")\n",
    "    )\n",
    "    # Text summary chain\n",
    "    model = VertexAI(\n",
    "        temperature=0, model_name=MODEL_NAME, max_output_tokens=1024\n",
    "    ).with_fallbacks([empty_response])\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts:\n",
    "        if summarize_texts:\n",
    "            text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
    "        else:\n",
    "            text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "# Get text, table summaries\n",
    "text_summaries, table_summaries = generate_text_summaries(\n",
    "    texts, tables, summarize_texts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91aeb4a9-a308-48a4-977d-c209ae1e4b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Getting the base64 string\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def image_summarize(img_base64, prompt):\n",
    "    \"\"\"Make image summary\"\"\"\n",
    "    model = ChatVertexAI(model_name=\"gemini-pro-vision\", max_output_tokens=1024)\n",
    "\n",
    "    msg = model(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/png;base64,{img_base64}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return msg.content\n",
    "\n",
    "\n",
    "def generate_img_summaries(path):\n",
    "    \"\"\"\n",
    "    Generate summaries and base64 encoded strings for images\n",
    "    path: Path to list of .jpg files extracted by Unstructured\n",
    "    \"\"\"\n",
    "\n",
    "    # Store base64 encoded images\n",
    "    img_base64_list = []\n",
    "\n",
    "    # Store image summaries\n",
    "    image_summaries = []\n",
    "\n",
    "    # Prompt\n",
    "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw image. \\\n",
    "    Give a concise summary of the image that is well optimized for retrieval.\n",
    "    If it's a table, extract all elements of the table.\n",
    "    If it's a graph, explain the findings in the graph.\n",
    "    Do not include any numbers that are not mentioned in the image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply to images\n",
    "    for img_file in sorted(os.listdir(path)):\n",
    "        if img_file.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "            base64_image = encode_image(img_path)\n",
    "            img_base64_list.append(base64_image)\n",
    "            image_summaries.append(image_summarize(base64_image, prompt))\n",
    "\n",
    "    return img_base64_list, image_summaries\n",
    "\n",
    "\n",
    "# Image summaries\n",
    "img_base64_list, image_summaries = generate_img_summaries(image_pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbfaa58d-369a-43a8-bcc3-7e17913bbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_all_texts = text_summaries + table_summaries + image_summaries \n",
    "joined_texts = \" \".join(combine_all_texts)\n",
    "texts_4k_token = text_splitter.split_text(joined_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3deb260-f4ad-4f8d-b1d4-089c6e8d0217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts_4k_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86fc7760-b2c5-47b6-941e-5d49ef2ad6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.create_documents(texts_4k_token)\n",
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cae88430-a45e-4c2d-90fe-55def3b67651",
   "metadata": {},
   "source": [
    "# Ingest Parent-Child node pairs (old) : all strategies failed\n",
    "parent_splitter = TokenTextSplitter(chunk_size=3000, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=750, chunk_overlap=24)\n",
    "parent_documents = parent_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44225643-c77a-410b-a0f2-a36da68d3921",
   "metadata": {},
   "source": [
    "# (old) : parent strategies failed\n",
    "parent_splitter = TokenTextSplitter(chunk_size=2048, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
    "parent_documents = parent_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2644d8d2-7467-48b0-a734-e4e232426416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest Parent-Child node pairs #  :all  passed\n",
    "parent_splitter = TokenTextSplitter(chunk_size=1024, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=256, chunk_overlap=24)\n",
    "parent_documents = parent_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bc019e4-8b47-45b2-8357-4a8269d2b819",
   "metadata": {},
   "source": [
    "# Ingest Parent-Child node pairs #  :all  passed\n",
    "parent_splitter = TokenTextSplitter(chunk_size=2048, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=1024, chunk_overlap=24)\n",
    "parent_documents = parent_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f98f4-b931-45d7-b7d4-0c96ce1c8fdc",
   "metadata": {},
   "source": [
    "parent_splitter = TokenTextSplitter(chunk_size=2048, chunk_overlap=24)\n",
    "child_splitter = TokenTextSplitter(chunk_size=1024, chunk_overlap=24)\n",
    "parent_documents = parent_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d185be8-9c11-4846-90e4-a204f8a3d6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85b261c7-4890-4168-af06-930f19495e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad5d19e0-9c69-4ba7-94f0-a4bb3c617101",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngraph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1cd64db4-ff27-4f6b-affd-206803df2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5118\n",
      "2012\n"
     ]
    }
   ],
   "source": [
    "for i, parent in enumerate(parent_documents):\n",
    "    child_documents = child_splitter.split_documents([parent])\n",
    "    print(len(parent.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f1ce532-21e7-42ef-a695-12a6020f2e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5118\n",
      "2012\n"
     ]
    }
   ],
   "source": [
    "for i, parent in enumerate(parent_documents):\n",
    "    child_documents = child_splitter.split_documents([parent])\n",
    "    print(len(parent.page_content))\n",
    "    params = {\n",
    "        \"parent_text\": parent.page_content,\n",
    "        \"parent_id\": i,\n",
    "        \"parent_embedding\": EMBEDDING_MODEL.embed_query(parent.page_content), #EMBEDDING_MODEL.get_embeddings([parent.page_content])[0].values,\n",
    "        \"children\": [\n",
    "            {\n",
    "                \"text\": c.page_content,\n",
    "                \"id\": f\"{i}-{ic}\",\n",
    "                \"embedding\": EMBEDDING_MODEL.embed_query(c.page_content) #EMBEDDING_MODEL.get_embeddings([c.page_content])[0].values,\n",
    "            }\n",
    "            for ic, c in enumerate(child_documents)\n",
    "        ],\n",
    "    }\n",
    "     # Ingest data\n",
    "    ngraph.query(\n",
    "        \"\"\"\n",
    "    MERGE (p:Parent {id: $parent_id})\n",
    "    SET p.text = $parent_text\n",
    "    WITH p\n",
    "    CALL db.create.setVectorProperty(p, 'embedding', $parent_embedding)\n",
    "    YIELD node\n",
    "    WITH p \n",
    "    UNWIND $children AS child\n",
    "    MERGE (c:Child {id: child.id})\n",
    "    SET c.text = child.text\n",
    "    MERGE (c)<-[:HAS_CHILD]-(p)\n",
    "    WITH c, child\n",
    "    CALL db.create.setVectorProperty(c, 'embedding', child.embedding)\n",
    "    YIELD node\n",
    "    RETURN count(*)\n",
    "    \"\"\",\n",
    "        params,\n",
    "    )\n",
    "    # Create vector index for child\n",
    "    try:\n",
    "        ngraph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('parent_document', \"\n",
    "            \"'Child', 'embedding', 768, 'cosine')\",\n",
    "            {},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n",
    "    # Create vector index for parents\n",
    "    try:\n",
    "        ngraph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('typical_rag', \"\n",
    "            \"'Parent', 'embedding', 768, 'cosine')\",\n",
    "            {},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n",
    "# CALL db.index.vector.createNodeIndex('parent_document', 'Child', 'embedding', 768, 'cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eac2a2-548d-4215-a225-3ab654f2e44b",
   "metadata": {},
   "source": [
    "![neo4j](./Summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedff08c-ef06-4340-a035-384707d88064",
   "metadata": {},
   "source": [
    "![neo4j](./Parent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20daf87c-cf75-433a-8ec5-b2609441bb10",
   "metadata": {},
   "source": [
    "![neo4j](./Child.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc0460c5-9c4e-4706-a4cf-5d2e694faacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatVertexAI(project='edl-idaas-rnd-platform-d5ae', model_name='gemini-1.5-pro-001', full_model_name='projects/edl-idaas-rnd-platform-d5ae/locations/us-central1/publishers/google/models/gemini-1.5-pro-001', client_options=ClientOptions: {'api_endpoint': 'us-central1-aiplatform.googleapis.com', 'client_cert_source': None, 'client_encrypted_cert_source': None, 'quota_project_id': None, 'credentials_file': None, 'scopes': None, 'api_key': None, 'api_audience': None, 'universe_domain': None}, default_metadata=(), model_family=<GoogleModelFamily.GEMINI_ADVANCED: '2'>, safety_settings={<HarmCategory.HARM_CATEGORY_HATE_SPEECH: 1>: <HarmBlockThreshold.BLOCK_LOW_AND_ABOVE: 1>})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fae3d93-1375-4f82-869e-9fafe233f0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb7a4e-9f76-44fe-a66e-310b98b1caa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8071fcc-20f7-48ab-90f4-05031c25308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest frequently asked questions  questions\n",
    "\n",
    "\n",
    "class Questions(BaseModel):\n",
    "    \"\"\"Generating hypothetical questions about text.\"\"\"\n",
    "\n",
    "    questions: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Generated hypothetical questions based on  the information from the text\"\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e389c9c9-8cf0-4d01-a11c-96dbccbdf42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Use the given format to generate frequently asked questions from the \"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "question_chain = questions_prompt | llm.with_structured_output(Questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d3b1808-a9da-40fc-9c84-ef382b7ca37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_chain = questions_prompt | llm.with_structured_output(Questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d8ebcd4f-653f-4a18-85e1-c3b0e411967b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43f19cd5-1e2e-430a-99d9-033bf51f4bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a6e05c9-4129-4a05-b59f-25521ebac1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the agreement about?', 'What are the key restrictions imposed by the agreement?', 'What happens to the confidential information after the agreement ends?', 'What are the legal implications of breaching the agreement?', 'Under what legal framework is this agreement established?']\n",
      "-------\n",
      "['What is the significance of the wavy line in the Halifax Regional Municipality logo?', 'What is the connection between the Halifax Regional Municipality logo and the content of the letter from the Chief Administrative Officer?', 'Why was a Non-Disclosure Agreement necessary between Halifax Regional Municipality and the Province of Nova Scotia in 2013?', 'What was the purpose of the meeting announced in the notice from David Greener and Martin Ward?', 'What is the process for the public to provide input during the public hearing on the proposed subdivision development?', 'What are the key proposed changes to the zoning regulations for the downtown area?', 'Who are David Greener and Martin Ward, and what are their roles within the Halifax Regional Municipality?', 'What is the meaning of \"SIGNED, SEALED AND DELIVERED\" in the context of the table?', 'Why is the document being signed in the presence of representatives from both the Province of Nova Scotia and the Halifax Regional Municipality?']\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for i, parent in enumerate(parent_documents):\n",
    "    resp = question_chain.invoke(parent.page_content)\n",
    "    if (resp != None):\n",
    "        questions = resp.questions\n",
    "        print(questions)\n",
    "        print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "acef9b53-0ef9-4cf2-8c67-1b4a0033baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, parent in enumerate(parent_documents):\n",
    "    resp = question_chain.invoke([parent.page_content])\n",
    "    if (resp != None):\n",
    "        questions = resp.questions\n",
    "        params = {\n",
    "            \"parent_id\": i,\n",
    "            \"questions\": [\n",
    "                {\"text\": q, \"id\": f\"{i}-{iq}\", \"embedding\": EMBEDDING_MODEL.embed_query(q)} #EMBEDDING_MODEL.get_embeddings([q])[0].values}\n",
    "                for iq, q in enumerate(questions)\n",
    "                if q\n",
    "            ],\n",
    "        }\n",
    "        ngraph.query(\n",
    "            \"\"\"\n",
    "        MERGE (p:Parent {id: $parent_id})\n",
    "        WITH p\n",
    "        UNWIND $questions AS question\n",
    "        CREATE (q:Question {id: question.id})\n",
    "        SET q.text = question.text\n",
    "        MERGE (q)<-[:HAS_QUESTION]-(p)\n",
    "        WITH q, question\n",
    "        CALL db.create.setVectorProperty(q, 'embedding', question.embedding)\n",
    "        YIELD node\n",
    "        RETURN count(*)\n",
    "        \"\"\",\n",
    "            params,\n",
    "        )\n",
    "        # Create vector index #CALL db.index.vector.createNodeIndex\n",
    "        try:\n",
    "            ngraph.query(\n",
    "                \"CALL db.index.vector.createNodeIndex('hypothetical_questions', \"\n",
    "                \"'Question', 'embedding', 768, 'cosine')\",\n",
    "                {},\n",
    "            )\n",
    "        except ClientError:  # already exists\n",
    "            pass\n",
    "#CALL db.index.vector.createNodeIndex('hypothetical_questions', 'Question', 'embedding', 768, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "027f0be0-c90a-4226-93c1-0ac9c057465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ingest summaries\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            (\"Generate a summary of the following input: {question}\\n\" \"Summary:\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "summary_chain = summary_prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9c4136d-bb5f-43e8-8831-6e737e454e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, parent in enumerate(parent_documents):\n",
    "    summary = summary_chain.invoke({\"question\": parent.page_content}).content\n",
    "    params = {\n",
    "        \"parent_id\": i,\n",
    "        \"summary\": summary,\n",
    "        \"embedding\": EMBEDDING_MODEL.embed_query(summary)# EMBEDDING_MODEL.get_embeddings([summary])[0].values,\n",
    "    }\n",
    "    ngraph.query(\n",
    "        \"\"\"\n",
    "    MERGE (p:Parent {id: $parent_id})\n",
    "    MERGE (p)-[:HAS_SUMMARY]->(s:Summary)\n",
    "    SET s.text = $summary\n",
    "    WITH s\n",
    "    CALL db.create.setVectorProperty(s, 'embedding', $embedding)\n",
    "    YIELD node\n",
    "    RETURN count(*)\n",
    "    \"\"\",\n",
    "        params,\n",
    "    )\n",
    "    # Create vector index\n",
    "    #CALL db.index.vector.createNodeIndex('typical_rag', 'Parent', 'embedding', 768, 'cosine')\n",
    "    try:\n",
    "        ngraph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('summary', \"\n",
    "            \"'Summary', 'embedding', 768, 'cosine')\",\n",
    "            {},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n",
    "# CALL db.index.vector.createNodeIndex('summary', 'Summary', 'embedding', 768, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98144a26-1833-4a29-a4bd-a820b96b0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical RAG retriever\n",
    "EMBEDDING_MODEL_NAME = 'textembedding-gecko@003'\n",
    "\n",
    "\n",
    "\n",
    "typical_rag = Neo4jVector.from_existing_index(\n",
    "    url = url,\n",
    "    username = username,\n",
    "    password = password,\n",
    "    embedding = VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
    "    index_name = 'typical_rag'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "82738c40-dac1-4b6f-a0a8-ea4df04ef336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_CHILD]-(parent)\n",
    "WITH parent, max(score) AS score // deduplicate parents\n",
    "RETURN parent.text AS text, score, {} AS metadata LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "parent_vectorstore = Neo4jVector.from_existing_index(\n",
    "    url = url,\n",
    "    username = username,\n",
    "    password = password,\n",
    "    embedding = VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
    "    index_name=\"parent_document\",\n",
    "    retrieval_query=parent_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d276f6b-84a6-4164-8100-b760358fe416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Hypothetic questions retriever\n",
    "\n",
    "hypothetic_question_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_QUESTION]-(parent)\n",
    "WITH parent, max(score) AS score // deduplicate parents\n",
    "RETURN parent.text AS text, score, {} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "hypothetic_question_vectorstore = Neo4jVector.from_existing_index(\n",
    "    url = url,\n",
    "    username = username,\n",
    "    password = password,\n",
    "    embedding = VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
    "    index_name=\"hypothetical_questions\",\n",
    "    retrieval_query=hypothetic_question_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "218ec595-bdf7-4e57-ab0e-4ad6a1ca7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # Summary retriever\n",
    "\n",
    "summary_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_SUMMARY]-(parent)\n",
    "WITH parent, max(score) AS score // deduplicate parents\n",
    "RETURN parent.text AS text, score, {} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "summary_vectorstore = Neo4jVector.from_existing_index(\n",
    "    url = url,\n",
    "    username = username,\n",
    "    password = password,\n",
    "    embedding = VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
    "    index_name=\"summary\",\n",
    "    retrieval_query=summary_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b259b4d-843f-42a3-b7ed-900286336555",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = typical_rag.as_retriever().configurable_alternatives(\n",
    "    ConfigurableField(id=\"strategy\"),\n",
    "    default_key=\"typical_rag\",\n",
    "    parent_strategy=parent_vectorstore.as_retriever(),\n",
    "    hypothetical_questions=hypothetic_question_vectorstore.as_retriever(),\n",
    "    summary_strategy=summary_vectorstore.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c72857d6-3104-4a13-bd73-4950e39aa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a482d0de-8b04-451a-bb3a-2f0cb75e9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your are a financial analyst Answer the question based only on the following context:\n",
    "{context}\n",
    "Use this above information to answer queries about contract between organizations and give details about dates, persons etc\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4f4a5f17-bb2a-4414-9553-e0e899cd552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.0-pro-vision\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    max_retries=6,\n",
    "    stop=None,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "73db2daa-52db-4c8c-bd2a-b0d841931fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever | format_docs,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33c78cf9-bd31-4322-8434-82137d990511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add typing for input\n",
    "class Question(BaseModel):\n",
    "    question: str\n",
    "\n",
    "\n",
    "chain = chain.with_types(input_type=Question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b9af9724-222e-4c2a-aabe-3fed2a15b0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Province of Nova Scotia\n",
      "* Halifax Regional Municipality\n"
     ]
    }
   ],
   "source": [
    "original_query = \"List the organizations involved?\"\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\"question\": original_query},\n",
    "        {\"configurable\": {\"strategy\": \"summary_strategy\"}},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "483ac45d-6ed0-45c3-a339-6a57b2cae06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document is signed by the Nova Scotia Minister of Finance, representing Her Majesty the Queen, and the Chief Administrative Officer of the Halifax Regional Municipality.\n"
     ]
    }
   ],
   "source": [
    "original_query = \"Who have signed this document?\"\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\"question\": original_query},\n",
    "        {\"configurable\": {\"strategy\": \"parent_strategy\"}},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8b18d626-9d10-426e-8896-bb8828dd7888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidentiality of information shared during discussions about the Province providing SAP services to HRM.\n"
     ]
    }
   ],
   "source": [
    "original_query = \"What is subject?\"\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\"question\": original_query},\n",
    "        {\"configurable\": {\"strategy\": \"hypothetical_questions\"}},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cccb06f7-6410-4242-990e-8134e0ef1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "June 25, 2013 Council authorization for the CAO to negotiate SAP support services with the Province.\n"
     ]
    }
   ],
   "source": [
    "original_query = \"What is origin?\"\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\"question\": original_query},\n",
    "        {\"configurable\": {\"strategy\": \"typical_rag\"}},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddb0a781-cff1-4241-904d-ac5245785f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meeting is scheduled for Tuesday, September 23, 2014 at 6:00 PM.\n"
     ]
    }
   ],
   "source": [
    "original_query = \"When is the meeting scheduled?\"\n",
    "print(\n",
    "    chain.invoke(\n",
    "        {\"question\": original_query},\n",
    "        {\"configurable\": {\"strategy\": \"parent_strategy\"}},\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f7092566-7a07-43c0-bc74-7b02e7d59c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_prompt = \"\"\"\n",
    "Generate a Cypher query to query a graph database based on the user's question {question}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "206c4053-d07f-43db-a9ae-c1310189a483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is subject?'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2e8799ca-c403-4c12-ad74-9a2be2ee83ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "allowed_nodes=[\"Person\", \"Country\", \"Organization\", \"Location\", \"Effective Date\", \"Signed Date\", \"heading\"],\n",
    "                                      allowed_relationships=[\"signed by\", \"Signed on\", \"Section\"]\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "The question is:\n",
    "{question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8c681867-e5ed-4877-98b4-0479c59cfddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b22d1557-a4d5-4e4f-b32f-6b0ef4edb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6aa629e-3c6f-4b2a-8863-fe24997ba0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = GraphCypherQAChain.from_llm(\n",
    "    ChatVertexAI(model='gemini-1.5-pro', max_output_tokens=8192, temperature=0.0),\n",
    "    graph=ngraph,\n",
    "    cypher_prompt=CYPHER_GENERATION_PROMPT,\n",
    "    verbose=True,\n",
    "    validate_cypher=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c843ec2c-46f2-476a-9239-eae412c1d58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (n:Organization) RETURN n\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'n': {'id': 'Mayor Savage and Members of Halifax Regional Council'}}, {'n': {'id': 'Halifax Regional Municipality'}}, {'n': {'id': 'Legal Services'}}, {'n': {'id': 'IBM'}}, {'n': {'id': 'Province of Nova Scotia'}}, {'n': {'id': 'Disclosing Party'}}, {'n': {'id': 'Receiving Party'}}, {'n': {'id': 'Halifax Regional Council'}}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'get all the Organization',\n",
       " 'result': 'Mayor Savage and Members of Halifax Regional Council, Halifax Regional Municipality, Legal Services, IBM, Province of Nova Scotia, Disclosing Party, Receiving Party, and Halifax Regional Council are all organizations. \\n'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"get all the Organization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436d1db-1060-4570-995d-db62cff4fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever | format_docs,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53309aa5-0295-406a-9fdb-e1aa72ba254f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
