{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0273c721-e075-44e9-8d6e-37b6b1cd708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --user --quiet google-cloud-aiplatform datasets backoff multiprocess gcsfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa967e6b-44b4-4f99-b327-fdbeee82895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3b4f33-bc98-40c8-b5ce-5f84f97c8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "from typing import Any, Callable, Dict, List, Optional, Union\n",
    "import io\n",
    "# Data Handling and Processing\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import gcsfs\n",
    "from google.cloud import storage\n",
    "\n",
    "# Google Cloud Libraries\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    GenerationConfig,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from vertexai.preview.tuning import sft\n",
    "\n",
    "# Multiprocessing\n",
    "import multiprocess as mp\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ede0a1-111c-413c-af07-0f1ea04cbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"train_40k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c30a3e7-844e-4787-8a76-22bd265ae5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c76dd86c-c22b-4e07-b8e2-b4f0fe11653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"productId\",\n",
    "    \"Title\",\n",
    "    \"userId\",\n",
    "    \"Helpfulness\",\n",
    "    \"Score\",\n",
    "    \"Time\",\n",
    "    \"Cat1\",\n",
    "]  # List of columns to drop\n",
    "data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47edb266-5ca2-4cb5-a11c-dea1db19cf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "464\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat2_classes = data[\"Cat2\"].unique()\n",
    "print(len(cat2_classes))\n",
    "\n",
    "cat3_classes = data[\"Cat3\"].unique()\n",
    "print(len(cat3_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a071e279-a591-4852-8972-dfb27cf555bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets (80% train, 20% test)\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the test data into another CSV file\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "test_df.to_csv(\"train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f809fe-f171-4aca-afe2-20bc4cf458ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"edl-idaas-rnd-platform-d5ae\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40fc9a5-5a9a-4f1d-b77c-8123be1f2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"sridhanya_edl-idaas-rnd-platform\"  # @param {type:\"string\"}\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb8ece6-1c1e-4744-abe6-122f048a28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b533027e-9300-4bb9-8779-e6136d5a6e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_hdlr(details) -> None:\n",
    "    \"\"\"\n",
    "    Handles backoff events.\n",
    "\n",
    "    Args:\n",
    "        details: A dictionary containing information about the backoff event.\n",
    "    \"\"\"\n",
    "    print(f\"Backing off {details['wait']:.1f} seconds after {details['tries']} tries\")\n",
    "\n",
    "\n",
    "def log_error(msg: str, *args: Any) -> None:\n",
    "    \"\"\"\n",
    "    Logs an error message and raises an exception.\n",
    "\n",
    "    Args:\n",
    "        msg: The error message.\n",
    "        *args: Additional arguments to be passed to the logger.\n",
    "    \"\"\"\n",
    "    mp.get_logger().error(msg, *args)\n",
    "    raise Exception(msg)\n",
    "\n",
    "\n",
    "def handle_exception_threading(f: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    A decorator that handles exceptions in a threaded environment.\n",
    "\n",
    "    Args:\n",
    "        f: The function to decorate.\n",
    "\n",
    "    Returns:\n",
    "        The decorated function.\n",
    "    \"\"\"\n",
    "\n",
    "    def applicator(*args: Any, **kwargs: Any) -> Any:\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            log_error(traceback.format_exc())\n",
    "\n",
    "    return applicator\n",
    "\n",
    "\n",
    "@handle_exception_threading\n",
    "@backoff.on_exception(\n",
    "    backoff.expo, ResourceExhausted, max_tries=30, on_backoff=backoff_hdlr\n",
    ")\n",
    "def _predict_message(message: str, model: GenerativeModel) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Predict messages\n",
    "\n",
    "    Args:\n",
    "        message: The message to predict.\n",
    "        model: The GenerativeModel to use for prediction.\n",
    "\n",
    "    Returns:\n",
    "        The predicted message, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    response = model.generate_content([message], stream=False)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def batch_predict(\n",
    "    messages: List[str], model: GenerativeModel, max_workers: int = 4\n",
    ") -> List[Optional[str]]:\n",
    "    \"\"\"\n",
    "    Predicts the classes for a list of messages\n",
    "\n",
    "    Args:\n",
    "        - messages: list of all messages to predict\n",
    "        - model: model to use for predicting.\n",
    "        - max_workers: number of workers to use for parallel predictions\n",
    "\n",
    "    Returns:\n",
    "        - list of predicted labels\n",
    "\n",
    "    \"\"\"\n",
    "    predictions = list()\n",
    "    with ThreadPoolExecutor(max_workers) as pool:\n",
    "        partial_func = partial(_predict_message, model=model)\n",
    "        for message in tqdm(pool.map(partial_func, messages), total=len(messages)):\n",
    "            predictions.append(message)\n",
    "            pass\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fffa5d-7749-4b93-b4f7-7bdb0f2bdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VertexAIExperimentManager:\n",
    "    \"\"\"\n",
    "    A class for managing experiments and runs in Vertex AI.\n",
    "    This class encapsulates the functionality for creating experiments, logging runs,\n",
    "    and retrieving experiment data in Vertex AI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, project: str, location: str):\n",
    "        self.project = project\n",
    "        self.location = location\n",
    "        self.current_experiment = None\n",
    "\n",
    "    def init_experiment(\n",
    "        self, experiment_name: str, experiment_description: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"Initialize or switch to a specific experiment.\"\"\"\n",
    "        self.current_experiment = experiment_name\n",
    "        aiplatform.init(\n",
    "            experiment=experiment_name,\n",
    "            experiment_description=experiment_description,\n",
    "            experiment_tensorboard=False,\n",
    "            project=self.project,\n",
    "            location=self.location,\n",
    "        )\n",
    "\n",
    "    def create_experiment(\n",
    "        self, experiment_name: str, experiment_description: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"Create an Experiment on Vertex AI Experiments\"\"\"\n",
    "        self.init_experiment(experiment_name, experiment_description)\n",
    "\n",
    "    def log_run(\n",
    "        self, run_name: str, params: Dict[str, Any], metrics: Dict[str, Any]\n",
    "    ) -> None:\n",
    "        \"\"\"Log experiment run data to Vertex AI Experiments.\"\"\"\n",
    "        if not self.current_experiment:\n",
    "            raise ValueError(\"No experiment initialized. Call init_experiment first.\")\n",
    "\n",
    "        aiplatform.start_run(run=run_name)\n",
    "        aiplatform.log_params(params)\n",
    "        aiplatform.log_metrics(metrics)\n",
    "        aiplatform.end_run()\n",
    "\n",
    "    def get_experiments_data_frame(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Retrieve a DataFrame of experiment data from Vertex AI Experiments.\"\"\"\n",
    "        if not self.current_experiment:\n",
    "            raise ValueError(\"No experiment initialized. Call init_experiment first.\")\n",
    "\n",
    "        return aiplatform.get_experiment_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "267bef06-c987-4ff7-98aa-47759a6436e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gemini_messages(\n",
    "    text: str, label: str, system_prompt: Optional[str] = None\n",
    ") -> dict:\n",
    "    messages = []\n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    messages.extend(\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "            {\"role\": \"model\", \"content\": label},\n",
    "        ]\n",
    "    )\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "def prepare_tuning_dataset_from_df(\n",
    "    tuning_df: pd.DataFrame, system_prompt: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares a tuning dataset from a pandas DataFrame for Gemini fine-tuning.\n",
    "    Args:\n",
    "        tuning_df: A pandas DataFrame with columns \"text\" and \"label_text\".\n",
    "        system_prompt: An optional system prompt for zero-shot learning.\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the data in the Gemini tuning format.\n",
    "    \"\"\"\n",
    "    tuning_dataset = [\n",
    "        create_gemini_messages(row[\"Text\"], row[\"Cat3\"], system_prompt)\n",
    "        for _, row in tuning_df.iterrows()\n",
    "    ]\n",
    "    return pd.DataFrame(tuning_dataset)\n",
    "\n",
    "\n",
    "def convert_tuning_dataset_from_automl_csv(\n",
    "    automl_gcs_csv_path: str,\n",
    "    system_prompt: Optional[str] = None,\n",
    "    partition: str = \"training\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts an AutoML CSV dataset for text classification to the Gemini tuning format.\n",
    "    Args:\n",
    "        automl_gcs_csv_path: The GCS path to the AutoML CSV dataset.\n",
    "        system_prompt: The instructions to the model.\n",
    "        partition: The partition to extract from the dataset (e.g., \"training\", \"validation\", \"test\"). Defaults to \"training\".\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the data in the Gemini tuning format.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(automl_gcs_csv_path, names=[\"partition\", \"Text\", \"Cat3\"])\n",
    "    df_automl = df.loc[df[\"partition\"] == partition]\n",
    "    gemini_dataset = [\n",
    "        create_gemini_messages(row[\"Text\"], row[\"Cat3\"], system_prompt)\n",
    "        for _, row in df_automl.iterrows()\n",
    "    ]\n",
    "    return pd.DataFrame(gemini_dataset)\n",
    "\n",
    "\n",
    "def convert_tuning_dataset_from_automl_jsonl(\n",
    "    project_id: str,\n",
    "    automl_gcs_jsonl_path: str,\n",
    "    system_prompt: Optional[str] = None,\n",
    "    partition: str = \"training\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts an AutoML JSONL dataset for text classification to the Gemini tuning format.\n",
    "    Args:\n",
    "        automl_gcs_jsonl_path: The GCS path to the AutoML JSONL dataset for text classification.\n",
    "        system_prompt: The instructions to the model.\n",
    "        partition: The partition to extract from the dataset (e.g., \"training\", \"validation\", \"test\"). Defaults to \"training\".\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the data in the Gemini tuning format.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    gcs_file_system = gcsfs.GCSFileSystem(project=project_id)\n",
    "    with gcs_file_system.open(automl_gcs_jsonl_path) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            processed_data.append(\n",
    "                {\n",
    "                    \"Cat3\": data[\"classificationAnnotation\"][\"displayName\"],\n",
    "                    \"Text\": data[\"textContent\"],\n",
    "                    \"partition\": data[\"dataItemResourceLabels\"][\n",
    "                        \"aiplatform.googleapis.com/ml_use\"\n",
    "                    ],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    df_automl = df.loc[df[\"partition\"] == partition]\n",
    "    gemini_dataset = [\n",
    "        create_gemini_messages(row[\"Text\"], row[\"Cat3\"], system_prompt)\n",
    "        for _, row in df_automl.iterrows()\n",
    "    ]\n",
    "    return pd.DataFrame(gemini_dataset)\n",
    "\n",
    "\n",
    "def validate_gemini_tuning_jsonl(gcs_jsonl_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Validates a JSONL file on Google Cloud Storage against the Gemini tuning format.\n",
    "\n",
    "    Args:\n",
    "        gcs_jsonl_path: The GCS path to the JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries representing the errors found in the file.\n",
    "        Each dictionary has the following structure:\n",
    "        {\n",
    "            \"error_type\": \"Error description\",\n",
    "            \"row_index\": The index of the row where the error occurred,\n",
    "            \"message\": The error message\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    errors = []\n",
    "    storage_client = storage.Client()\n",
    "    blob = storage.Blob.from_string(uri=gcs_jsonl_path, client=storage_client)\n",
    "\n",
    "    with blob.open(\"r\") as f:\n",
    "        for row_index, line in enumerate(f):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                # Check for the presence of the \"messages\" key\n",
    "                if \"messages\" not in data:\n",
    "                    errors.append(\n",
    "                        {\n",
    "                            \"error_type\": \"Missing 'messages' key\",\n",
    "                            \"row_index\": row_index,\n",
    "                            \"message\": f\"Row {row_index} is missing the 'messages' key.\",\n",
    "                        }\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                messages = data[\"messages\"]\n",
    "                # Check if \"messages\" is a list\n",
    "                if not isinstance(messages, list):\n",
    "                    errors.append(\n",
    "                        {\n",
    "                            \"error_type\": \"Invalid 'messages' type\",\n",
    "                            \"row_index\": row_index,\n",
    "                            \"message\": f\"Row {row_index}: 'messages' is not a list.\",\n",
    "                        }\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Validate each message in the \"messages\" list\n",
    "                for message_index, message in enumerate(messages):\n",
    "                    if not isinstance(message, dict):\n",
    "                        errors.append(\n",
    "                            {\n",
    "                                \"error_type\": \"Invalid message format\",\n",
    "                                \"row_index\": row_index,\n",
    "                                \"message\": f\"\"\"Row {row_index},\n",
    "                            message {message_index}: Message is not a dictionary.\"\"\",\n",
    "                            }\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    # Check for required keys in each message dictionary\n",
    "                    if \"role\" not in message or \"content\" not in message:\n",
    "                        errors.append(\n",
    "                            {\n",
    "                                \"error_type\": \"Missing 'role' or 'content' key\",\n",
    "                                \"row_index\": row_index,\n",
    "                                \"message\": f\"Row {row_index}, message {message_index}: \"\n",
    "                                \"Missing 'role' or 'content' key.\",\n",
    "                            }\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    # Check for valid role values\n",
    "                    if message[\"role\"] not in [\"system\", \"user\", \"model\"]:\n",
    "                        errors.append(\n",
    "                            {\n",
    "                                \"error_type\": \"Invalid 'role' value\",\n",
    "                                \"row_index\": row_index,\n",
    "                                \"message\": f\"\"\"Row {row_index}, message {message_index}:\n",
    "                            Invalid 'role' value. Expected 'system', 'user', or 'model'.\"\"\",\n",
    "                            }\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                errors.append(\n",
    "                    {\n",
    "                        \"error_type\": \"JSON Decode Error\",\n",
    "                        \"row_index\": row_index,\n",
    "                        \"message\": f\"Row {row_index}: JSON decoding error: {e}\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fba6e88-a675-4f0a-9010-deee452e9aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b3cce57-e337-429e-a840-96cc79e6ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3dd0850-e515-46bd-97eb-0ed40e84ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cat2</th>\n",
       "      <th>Cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14307</th>\n",
       "      <td>The concept of this toy is good. However, if y...</td>\n",
       "      <td>dogs</td>\n",
       "      <td>toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17812</th>\n",
       "      <td>This dryer ruined my hair!!! At first, after I...</td>\n",
       "      <td>hair care</td>\n",
       "      <td>styling tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>Much to my surprise after a year of waiting th...</td>\n",
       "      <td>novelty gag toys</td>\n",
       "      <td>miniatures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15158</th>\n",
       "      <td>The tree is beautiful but upon arrival when I ...</td>\n",
       "      <td>fresh flowers live indoor plants</td>\n",
       "      <td>live indoor plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>Watchmaker offered to install a new battery in...</td>\n",
       "      <td>household supplies</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "14307  The concept of this toy is good. However, if y...   \n",
       "17812  This dryer ruined my hair!!! At first, after I...   \n",
       "11020  Much to my surprise after a year of waiting th...   \n",
       "15158  The tree is beautiful but upon arrival when I ...   \n",
       "24990  Watchmaker offered to install a new battery in...   \n",
       "\n",
       "                                   Cat2                Cat3  \n",
       "14307                              dogs                toys  \n",
       "17812                         hair care       styling tools  \n",
       "11020                  novelty gag toys          miniatures  \n",
       "15158  fresh flowers live indoor plants  live indoor plants  \n",
       "24990                household supplies             unknown  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bee6f4b8-361a-4417-972c-b6a0d0304e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat2\n",
       "personal care         2294\n",
       "dogs                  2092\n",
       "nutrition wellness    1780\n",
       "health care           1614\n",
       "cats                  1428\n",
       "                      ... \n",
       "produce                 33\n",
       "baby food               32\n",
       "sauces dips             32\n",
       "meat seafood            25\n",
       "small animals           22\n",
       "Name: count, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Cat2.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901ca963-23c7-436e-836e-101365e47972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat3\n",
       "unknown                 1832\n",
       "shaving hair removal    1238\n",
       "vitamins supplements    1071\n",
       "board games              738\n",
       "styling tools            670\n",
       "                        ... \n",
       "fruit gifts                1\n",
       "foie gras p t s            1\n",
       "children s                 1\n",
       "aprons smocks              1\n",
       "pork                       1\n",
       "Name: count, Length: 451, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Cat3.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a745bd3c-7201-4d26-9295-c80e21e357c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = test_df.groupby(\"Cat3\").filter(lambda x: len(x) > 1)\n",
    "val, test = train_test_split(\n",
    "    filtered_df, test_size=0.75, shuffle=True, stratify=filtered_df[\"Cat3\"], random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48cf56a5-27b7-4069-8f68-51b11b71cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "val1=val[0:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6554416b-6f5e-4a97-9df5-0405bc81a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1982, 3)\n",
      "(5946, 3)\n"
     ]
    }
   ],
   "source": [
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d108500-8800-49c8-8141-8c02e90c80ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat3\n",
       "unknown                   108\n",
       "shaving hair removal       82\n",
       "vitamins supplements       61\n",
       "board games                47\n",
       "styling tools              45\n",
       "                         ... \n",
       "cakes                       1\n",
       "basic life skills toys      1\n",
       "fruit leather               1\n",
       "joggers                     1\n",
       "aquarium heaters            1\n",
       "Name: count, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.Cat3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f61b0b6b-69d3-4769-a184-8507b035a3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat3\n",
       "unknown                 322\n",
       "shaving hair removal    245\n",
       "vitamins supplements    183\n",
       "board games             139\n",
       "styling tools           135\n",
       "                       ... \n",
       "washcloths towels         1\n",
       "snack gifts               1\n",
       "money banks               1\n",
       "crackers biscuits         1\n",
       "stimulants                1\n",
       "Name: count, Length: 320, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Cat3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8e4ce16-f307-46af-ae22-8b52486072c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_postprocessing(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans the predicted class label string.\n",
    "\n",
    "    Args:\n",
    "        text (str): The predicted class label string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned class label string.\n",
    "    \"\"\"\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "def evaluate_predictions(\n",
    "    df: pd.DataFrame,\n",
    "    target_column: str = \"label_text\",\n",
    "    predictions_column: str = \"predicted_labels\",\n",
    "    postprocessing: bool = True,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Batch evaluation of predictions, returns a dictionary with the metric.\n",
    "\n",
    "    Args:\n",
    "       - df (pandas.DataFrame):  a pandas dataframe with two mandatory columns, a target column with\n",
    "       the actual true values, and a predictions column with the predicted values.\n",
    "       - target_column (str): column name with the actual ground truth values\n",
    "       - predictions_column (str): column name with the model predictions\n",
    "       - postprocessing (bool): whether to apply postprocessing to predictions.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary of evaluation metrics.\n",
    "    \"\"\"\n",
    "    if postprocessing:\n",
    "        df[predictions_column] = df[predictions_column].apply(\n",
    "            predictions_postprocessing\n",
    "        )\n",
    "\n",
    "    y_true = df[target_column]\n",
    "    y_pred = df[predictions_column]\n",
    "\n",
    "    metrics_report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    overall_macro_f1_score = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    overall_micro_f1_score = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    weighted_precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "    weighted_recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": metrics_report[\"accuracy\"],\n",
    "        \"weighted precision\": weighted_precision,\n",
    "        \"weighted recall\": weighted_recall,\n",
    "        \"macro f1\": overall_macro_f1_score,\n",
    "        \"micro f1\": overall_micro_f1_score,\n",
    "    }\n",
    "\n",
    "    categories = [\"business\", \"sport\", \"politics\", \"tech\", \"entertainment\"]\n",
    "    for category in categories:\n",
    "        if category in metrics_report:\n",
    "            metrics[f\"{category}_f1_score\"] = metrics_report[category][\"f1-score\"]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f818802-24a0-4872-aa71-1ef2ed7e2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"sridhanya-classification\"  # @param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61ea1ffe-8ac2-4ef8-8a46-bef33c45cd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-0386289f-ab23-409e-95ff-7ef977eaefee\" href=\"#view-view-vertex-resource-0386289f-ab23-409e-95ff-7ef977eaefee\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-0386289f-ab23-409e-95ff-7ef977eaefee');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/sridhanya-classification/runs?project=edl-idaas-rnd-platform-d5ae');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/sridhanya-classification/runs?project=edl-idaas-rnd-platform-d5ae', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_manager = VertexAIExperimentManager(project=PROJECT_ID, location=LOCATION)\n",
    "experiment_manager.create_experiment(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    experiment_description=\"Fine-tuning Gemini 1.0 Pro for text classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af5fa203-494d-4e05-b752-82cc877ec674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Evaluation dataframe to store the predictions from all the experiments.\n",
    "df_evals = val[0:50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92d2cd8d-d548-4deb-abe9-ba8601af6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the classes into a string\n",
    "classes_list_str = \"\\n- \".join(cat3_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a224a3-d0d0-4d69-b124-665f6afde955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first index for each unique category in 'Cat3'\n",
    "first_indices = train_df.drop_duplicates(subset='Cat3').index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e5ae639-6448-4e76-8d2f-7491f7c0bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_zero_shot = f\"\"\"TASK:\n",
    "Classify the text into ONLY one of the following classes .\n",
    "\n",
    "CLASSES:\n",
    "- {classes_list_str}\n",
    "\n",
    "\n",
    "INSTRUCTIONS\n",
    "- Respond with ONLY one class.\n",
    "- You MUST use the exact word from the list above.\n",
    "- DO NOT create or use any other classes.\n",
    "- CAREFULLY analyze the text before choosing the best-fitting category.\n",
    "\n",
    "\"\"\".format(classes_list_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10058039-13e0-4be6-8f9f-602f05683723",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_few_shot = f\"\"\"TASK:\n",
    "Classify the text into ONLY one of the following classes [business, entertainment, politics, sport, tech].\n",
    "\n",
    "CLASSES:\n",
    "- {classes_list_str}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- Respond with ONLY one class.\n",
    "- You MUST use the exact word from the list above.\n",
    "- DO NOT create or use any other classes.\n",
    "- CAREFULLY analyze the text before choosing the best-fitting category.\n",
    "\n",
    "EXAMPLES:\n",
    "- EXAMPLE 1:\n",
    "    <user>\n",
    "    {train_df.loc[first_indices[0]].Text}\n",
    "    <model>\n",
    "    {train_df.loc[first_indices[0]].Cat3}\n",
    "\n",
    "- EXAMPLE 2:\n",
    "    <user>\n",
    "    {train_df.loc[first_indices[1]].Text}\n",
    "    <model>\n",
    "    {train_df.loc[first_indices[1]].Cat3}\n",
    "\n",
    "- EXAMPLE 3:\n",
    "    <user>\n",
    "    {train_df.loc[first_indices[2]].Text}\n",
    "    <model>\n",
    "    {train_df.loc[first_indices[21]].Cat3}\n",
    "\n",
    "- EXAMPLE 4:\n",
    "    <user>\n",
    "    {train_df.loc[first_indices[3]].Text}\n",
    "    <model>\n",
    "    {train_df.loc[first_indices[31]].Cat3}\n",
    "\n",
    "- EXAMPLE 4:\n",
    "    <user>\n",
    "    {train_df.loc[first_indices[4]].Text}\n",
    "    <model>\n",
    "    {train_df.loc[first_indices[4]].Cat3}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cd53606-29a2-4936-9ce7-5e19a6d28110",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(max_output_tokens=10, temperature=0)\n",
    "\n",
    "safety_settings = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2048640d-a012-441b-a735-4ead564a8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gem_pro_1_model_zero = GenerativeModel(\n",
    "    \"gemini-1.0-pro-002\",  # e.g. gemini-1.5-pro-001, gemini-1.5-flash-001\n",
    "    system_instruction=[system_prompt_zero_shot],\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4bc870b-d7df-42f0-90d1-1cbe7f34dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the list of messages to predict\n",
    "messages_to_predict = val[\"Text\"][0:50].to_list()\n",
    "# Compute the preictions\n",
    "predictions_zero_shot = batch_predict(\n",
    "    messages=messages_to_predict, model=gem_pro_1_model_zero, max_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c272b55-4da4-4973-b20c-b4c5f565c367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evals[\"gem1.0-zero-shot_predictions\"] = predictions_zero_shot\n",
    "len(predictions_zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26851424-7d58-4f5c-8333-456beaeb5ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.22,\n",
       " 'weighted precision': 0.231,\n",
       " 'weighted recall': 0.22,\n",
       " 'macro f1': 0.09487734487734488,\n",
       " 'micro f1': 0.22}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Evaluation Metrics for zero-shot prompt\n",
    "metrics_zero_shot = evaluate_predictions(\n",
    "    df_evals.copy(),\n",
    "    target_column=\"Cat3\",\n",
    "    predictions_column=\"gem1.0-zero-shot_predictions\",\n",
    "    postprocessing=True,\n",
    ")\n",
    "metrics_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43899e58-18a7-43af-9550-ea53306eb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Few-Shot, and other prompts/possibilities\n",
    "gem_pro_1_model_few = GenerativeModel(\n",
    "    \"gemini-1.0-pro-002\",\n",
    "    system_instruction=[system_prompt_few_shot],\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc7d4044-1075-4f76-bea9-5690e00d0f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.52it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_few_shot = batch_predict(\n",
    "    messages=messages_to_predict, model=gem_pro_1_model_few\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8486ee96-5b8f-4ca9-821e-f3ff9428b521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evals[\"gem1.0-few-shot_predictions\"] = predictions_few_shot\n",
    "len(predictions_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a422445c-66aa-4e64-8e32-3ec00d8abec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/envs/llm/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.2,\n",
       " 'weighted precision': 0.17615384615384613,\n",
       " 'weighted recall': 0.2,\n",
       " 'macro f1': 0.1346153846153846,\n",
       " 'micro f1': 0.2}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Evaluation Metrics for few-shot prompt\n",
    "metrics_few_shot = evaluate_predictions(\n",
    "    df_evals.copy(),\n",
    "    target_column=\"Cat3\",\n",
    "    predictions_column=\"gem1.0-few-shot_predictions\",\n",
    "    postprocessing=True,\n",
    ")\n",
    "metrics_few_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa1ce220-0a57-4d54-8439-2e1a34a4f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_gemini_df = prepare_tuning_dataset_from_df(\n",
    "    tuning_df=train_df, system_prompt=system_prompt_zero_shot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61bcab1c-afc3-44eb-86c4-93961ba217d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages\n",
       "0  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "1  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "2  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "3  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "4  [{'role': 'system', 'content': 'TASK:\n",
       "Classify..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_gemini_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "086222a5-790b-4324-9a9c-7f8b7b3250f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store tuning dataset in GCS\n",
    "tuning_data_gcs_path = f\"gs://india-dev-rnd/sridhanya/vm/Assignment/tuning_experiments/tuning_dataset_gemini.jsonl\"  # @param {type: \"string\"}\n",
    "\n",
    "tuning_gemini_df.to_json(tuning_data_gcs_path, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22336966-6048-4784-ac2a-df1845871238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_gemini_tuning_jsonl(gcs_jsonl_path=tuning_data_gcs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2e8151f-6392-40ba-859d-f680c5269649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'role': 'system', 'content': 'TASK:\n",
       "Classify...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages\n",
       "0  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "1  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "2  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "3  [{'role': 'system', 'content': 'TASK:\n",
       "Classify...\n",
       "4  [{'role': 'system', 'content': 'TASK:\n",
       "Classify..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_gemini_df = prepare_tuning_dataset_from_df(\n",
    "    tuning_df=val1, system_prompt=system_prompt_zero_shot\n",
    ")\n",
    "validation_gemini_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d88ce5e9-f312-4d5b-80b1-e06e55eafba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_gemini_df.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0a46af9-d24e-49f6-95e2-72db1a993092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store validation dataset in GCS\n",
    "validation_data_gcs_path = f\"gs://india-dev-rnd/sridhanya/vm/Assignment/val_tuning_experiments/validation_dataset_gemini.jsonl\"  # @param {type: \"string\"}\n",
    "validation_gemini_df.to_json(validation_data_gcs_path, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa9f3203-f123-4d58-95de-24559c42589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_gemini_df.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d4cc2ef-d40b-4c71-a25d-88c6210ae765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_gemini_tuning_jsonl(gcs_jsonl_path=validation_data_gcs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39fff3fb-ecae-47a2-a5f8-a1fee2c65223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune a model using `train` method.\n",
    "\n",
    "tuned_model_name = \"sridhanya-classification\"  # @param {type: \"string\"}\n",
    "epochs = 4  # @param\n",
    "learning_rate_multiplier = 1  # @param\n",
    "adapter_size = 1  # @param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27236a00-6d81-4f20-aceb-e7cb030c3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/199599498795/locations/us-central1/tuningJobs/7335713878535307264\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/199599498795/locations/us-central1/tuningJobs/7335713878535307264')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/7335713878535307264?project=199599498795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-eac57a85-b3e2-4223-ba81-edaf489b5dc4\" href=\"#view-view-vertex-resource-eac57a85-b3e2-4223-ba81-edaf489b5dc4\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-eac57a85-b3e2-4223-ba81-edaf489b5dc4');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/7335713878535307264?project=199599498795');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/7335713878535307264?project=199599498795', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/199599498795/locations/us-central1/tuningJobs/7335713878535307264',\n",
       " 'tunedModelDisplayName': 'sridhanya-classification',\n",
       " 'baseModel': 'gemini-1.0-pro-002',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://india-dev-rnd/sridhanya/vm/Assignment/tuning_experiments/tuning_dataset_gemini.jsonl',\n",
       "  'validationDatasetUri': 'gs://india-dev-rnd/sridhanya/vm/Assignment/val_tuning_experiments/validation_dataset_gemini.jsonl',\n",
       "  'hyperParameters': {'epochCount': '4',\n",
       "   'learningRateMultiplier': 1.0,\n",
       "   'adapterSize': 'ADAPTER_SIZE_ONE'}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2024-08-22T09:34:29.021125Z',\n",
       " 'updateTime': '2024-08-22T09:34:29.021125Z'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_tuning_job = sft.train(\n",
    "    tuned_model_display_name=tuned_model_name,\n",
    "    source_model=\"gemini-1.0-pro-002\",\n",
    "    train_dataset=tuning_data_gcs_path,\n",
    "    # Optional:\n",
    "    validation_dataset=validation_data_gcs_path,\n",
    "    epochs=epochs,\n",
    "    learning_rate_multiplier=learning_rate_multiplier,\n",
    "    adapter_size=adapter_size,\n",
    ")\n",
    "\n",
    "# Get the tuning job info.\n",
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f60d9400-d7e1-48e3-8d16-cdaac49573c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/199599498795/locations/us-central1/tuningJobs/7335713878535307264'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the resource name of the tuning job\n",
    "sft_tuning_job_name = sft_tuning_job.resource_name\n",
    "sft_tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26265cea-8eea-480b-9595-509571b857f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-b18dae70-fce7-482d-b04d-6957350054a3\" href=\"#view-view-vertex-resource-b18dae70-fce7-482d-b04d-6957350054a3\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-b18dae70-fce7-482d-b04d-6957350054a3');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/7335713878535307264?project=199599498795');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/7335713878535307264?project=199599498795', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get tuning job\n",
    "TUNING_JOB_ID = \"1018008026264633344\"  # @param example 952462564720115710\n",
    "sft_tuning_job = sft.SupervisedTuningJob(\n",
    "    f\"projects/199599498795/locations/us-central1/tuningJobs/7335713878535307264\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32d36479-9b79-432b-956d-bfcaf713db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/199599498795/locations/us-central1/endpoints/4603380307591168000'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuned model endpoint name\n",
    "tuned_model_endpoint_name = sft_tuning_job.tuned_model_endpoint_name\n",
    "tuned_model_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e40741e9-f437-4680-8654-e14441daf1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/199599498795/locations/us-central1/models/248358785993670656@1'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuned model name\n",
    "tuned_model_name = sft_tuning_job.tuned_model_name\n",
    "tuned_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f21a3883-6133-4409-b77d-15ce4622f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gemini_pro = GenerativeModel(\n",
    "    tuned_model_endpoint_name,\n",
    "    system_instruction=[system_prompt_zero_shot],\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce0c7482-73c6-45ed-9fcf-77424e593235",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tuned_gemini_pro.generate_content([test[\"Text\"].iloc[4]], stream=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db1803b4-49e6-4ac9-ad85-02d6f44114ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted eye care\n",
      "ground truth eye care\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted\", response.text)\n",
    "print(\"ground truth\", test[\"Cat3\"].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e7b177d1-79b0-4ce9-a1f7-fc8504b7fb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 57/5946 [00:17<23:10,  4.23it/s] Traceback (most recent call last):\n",
      "  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1976, in text\n",
      "    return self.content.text\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 2055, in text\n",
      "    raise ValueError(\n",
      "ValueError: Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\n",
      "Content:\n",
      "{}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1890, in text\n",
      "    return self.candidates[0].text\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1980, in text\n",
      "    raise ValueError(\n",
      "ValueError: Cannot get the Candidate text.\n",
      "Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\n",
      "Content:\n",
      "{}\n",
      "Candidate:\n",
      "{\n",
      "  \"finish_reason\": \"SAFETY\",\n",
      "  \"safety_ratings\": [\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "      \"probability\": \"NEGLIGIBLE\",\n",
      "      \"probability_score\": 0.21783626,\n",
      "      \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "      \"severity_score\": 0.21601154\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "      \"probability\": \"NEGLIGIBLE\",\n",
      "      \"probability_score\": 0.2757144,\n",
      "      \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "      \"severity_score\": 0.21502088\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "      \"probability\": \"NEGLIGIBLE\",\n",
      "      \"probability_score\": 0.23126681,\n",
      "      \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "      \"severity_score\": 0.21255875\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "      \"probability\": \"HIGH\",\n",
      "      \"blocked\": true,\n",
      "      \"probability_score\": 0.9150529,\n",
      "      \"severity\": \"HARM_SEVERITY_HIGH\",\n",
      "      \"severity_score\": 0.755637\n",
      "    }\n",
      "  ],\n",
      "  \"avg_logprobs\": \"NaN\"\n",
      "}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/tmp/ipykernel_196284/750188219.py\", line 36, in applicator\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/backoff/_sync.py\", line 105, in retry\n",
      "    ret = target(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/tmp/ipykernel_196284/750188219.py\", line 59, in _predict_message\n",
      "    return response.text\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1894, in text\n",
      "    raise ValueError(\n",
      "ValueError: Cannot get the response text.\n",
      "Cannot get the Candidate text.\n",
      "Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\n",
      "Content:\n",
      "{}\n",
      "Candidate:\n",
      "{\n",
      "  \"finish_reason\": \"SAFETY\",\n",
      "  \"safety_ratings\": [\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "      \"probability\": \"NEGLIGIBLE\",\n",
      "      \"probability_score\": 0.21783626,\n",
      "      \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "      \"severity_score\": 0.21601154\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "      \"probability\": \"NEGLIGIBLE\",\n",
      "      \"probability_score\": 0.2757144,\n",
      "      \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "      \"severity_score\": 0.21502088\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "      \"probability\": \"NEGLIGIBLE\",\n",
      "      \"probability_score\": 0.23126681,\n",
      "      \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "      \"severity_score\": 0.21255875\n",
      "    },\n",
      "    {\n",
      "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "      \"probability\": \"HIGH\",\n",
      "      \"blocked\": true,\n",
      "      \"probability_score\": 0.9150529,\n",
      "      \"severity\": \"HARM_SEVERITY_HIGH\",\n",
      "      \"severity_score\": 0.755637\n",
      "    }\n",
      "  ],\n",
      "  \"avg_logprobs\": \"NaN\"\n",
      "}\n",
      "Response:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"finish_reason\": \"SAFETY\",\n",
      "      \"safety_ratings\": [\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probability_score\": 0.21783626,\n",
      "          \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "          \"severity_score\": 0.21601154\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probability_score\": 0.2757144,\n",
      "          \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "          \"severity_score\": 0.21502088\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "          \"probability\": \"NEGLIGIBLE\",\n",
      "          \"probability_score\": 0.23126681,\n",
      "          \"severity\": \"HARM_SEVERITY_LOW\",\n",
      "          \"severity_score\": 0.21255875\n",
      "        },\n",
      "        {\n",
      "          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "          \"probability\": \"HIGH\",\n",
      "          \"blocked\": true,\n",
      "          \"probability_score\": 0.9150529,\n",
      "          \"severity\": \"HARM_SEVERITY_HIGH\",\n",
      "          \"severity_score\": 0.755637\n",
      "        }\n",
      "      ],\n",
      "      \"avg_logprobs\": \"NaN\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage_metadata\": {\n",
      "    \"prompt_token_count\": 2065,\n",
      "    \"total_token_count\": 2065\n",
      "  }\n",
      "}\n",
      "\n",
      "  1%|          | 61/5946 [00:18<29:33,  3.32it/s]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Traceback (most recent call last):\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1976, in text\n    return self.content.text\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 2055, in text\n    raise ValueError(\nValueError: Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1890, in text\n    return self.candidates[0].text\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1980, in text\n    raise ValueError(\nValueError: Cannot get the Candidate text.\nResponse candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\nCandidate:\n{\n  \"finish_reason\": \"SAFETY\",\n  \"safety_ratings\": [\n    {\n      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.21783626,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21601154\n    },\n    {\n      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.2757144,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21502088\n    },\n    {\n      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.23126681,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21255875\n    },\n    {\n      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n      \"probability\": \"HIGH\",\n      \"blocked\": true,\n      \"probability_score\": 0.9150529,\n      \"severity\": \"HARM_SEVERITY_HIGH\",\n      \"severity_score\": 0.755637\n    }\n  ],\n  \"avg_logprobs\": \"NaN\"\n}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/tmp/ipykernel_196284/750188219.py\", line 36, in applicator\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/backoff/_sync.py\", line 105, in retry\n    ret = target(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/tmp/ipykernel_196284/750188219.py\", line 59, in _predict_message\n    return response.text\n           ^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1894, in text\n    raise ValueError(\nValueError: Cannot get the response text.\nCannot get the Candidate text.\nResponse candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\nCandidate:\n{\n  \"finish_reason\": \"SAFETY\",\n  \"safety_ratings\": [\n    {\n      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.21783626,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21601154\n    },\n    {\n      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.2757144,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21502088\n    },\n    {\n      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.23126681,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21255875\n    },\n    {\n      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n      \"probability\": \"HIGH\",\n      \"blocked\": true,\n      \"probability_score\": 0.9150529,\n      \"severity\": \"HARM_SEVERITY_HIGH\",\n      \"severity_score\": 0.755637\n    }\n  ],\n  \"avg_logprobs\": \"NaN\"\n}\nResponse:\n{\n  \"candidates\": [\n    {\n      \"finish_reason\": \"SAFETY\",\n      \"safety_ratings\": [\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.21783626,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21601154\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.2757144,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21502088\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.23126681,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21255875\n        },\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"probability\": \"HIGH\",\n          \"blocked\": true,\n          \"probability_score\": 0.9150529,\n          \"severity\": \"HARM_SEVERITY_HIGH\",\n          \"severity_score\": 0.755637\n        }\n      ],\n      \"avg_logprobs\": \"NaN\"\n    }\n  ],\n  \"usage_metadata\": {\n    \"prompt_token_count\": 2065,\n    \"total_token_count\": 2065\n  }\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1976\u001b[0m, in \u001b[0;36mCandidate.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1975\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1978\u001b[0m     \u001b[38;5;66;03m# Enrich the error message with the whole Candidate.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m     \u001b[38;5;66;03m# The Content object does not have full information.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:2055\u001b[0m, in \u001b[0;36mContent.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts:\n\u001b[0;32m-> 2055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2056\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse candidate content has no parts (and thus no text).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2057\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m The candidate is likely blocked by the safety filters.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m _dict_to_pretty_string(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m   2059\u001b[0m     )\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "\u001b[0;31mValueError\u001b[0m: Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1890\u001b[0m, in \u001b[0;36mGenerationResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;66;03m# Enrich the error message with the whole Response.\u001b[39;00m\n\u001b[1;32m   1893\u001b[0m     \u001b[38;5;66;03m# The Candidate object does not have full information.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1980\u001b[0m, in \u001b[0;36mCandidate.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1978\u001b[0m     \u001b[38;5;66;03m# Enrich the error message with the whole Candidate.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m     \u001b[38;5;66;03m# The Content object does not have full information.\u001b[39;00m\n\u001b[0;32m-> 1980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1981\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get the Candidate text.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1982\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m _dict_to_pretty_string(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m   1984\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot get the Candidate text.\nResponse candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\nCandidate:\n{\n  \"finish_reason\": \"SAFETY\",\n  \"safety_ratings\": [\n    {\n      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.21783626,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21601154\n    },\n    {\n      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.2757144,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21502088\n    },\n    {\n      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.23126681,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21255875\n    },\n    {\n      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n      \"probability\": \"HIGH\",\n      \"blocked\": true,\n      \"probability_score\": 0.9150529,\n      \"severity\": \"HARM_SEVERITY_HIGH\",\n      \"severity_score\": 0.755637\n    }\n  ],\n  \"avg_logprobs\": \"NaN\"\n}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mhandle_exception_threading.<locals>.applicator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/backoff/_sync.py:105\u001b[0m, in \u001b[0;36mretry_exception.<locals>.retry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exception \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[10], line 59\u001b[0m, in \u001b[0;36m_predict_message\u001b[0;34m(message, model)\u001b[0m\n\u001b[1;32m     58\u001b[0m response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content([message], stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:1894\u001b[0m, in \u001b[0;36mGenerationResponse.text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;66;03m# Enrich the error message with the whole Response.\u001b[39;00m\n\u001b[1;32m   1893\u001b[0m     \u001b[38;5;66;03m# The Candidate object does not have full information.\u001b[39;00m\n\u001b[0;32m-> 1894\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1895\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get the response text.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1896\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1897\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m _dict_to_pretty_string(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m   1898\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot get the response text.\nCannot get the Candidate text.\nResponse candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\nCandidate:\n{\n  \"finish_reason\": \"SAFETY\",\n  \"safety_ratings\": [\n    {\n      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.21783626,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21601154\n    },\n    {\n      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.2757144,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21502088\n    },\n    {\n      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.23126681,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21255875\n    },\n    {\n      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n      \"probability\": \"HIGH\",\n      \"blocked\": true,\n      \"probability_score\": 0.9150529,\n      \"severity\": \"HARM_SEVERITY_HIGH\",\n      \"severity_score\": 0.755637\n    }\n  ],\n  \"avg_logprobs\": \"NaN\"\n}\nResponse:\n{\n  \"candidates\": [\n    {\n      \"finish_reason\": \"SAFETY\",\n      \"safety_ratings\": [\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.21783626,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21601154\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.2757144,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21502088\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.23126681,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21255875\n        },\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"probability\": \"HIGH\",\n          \"blocked\": true,\n          \"probability_score\": 0.9150529,\n          \"severity\": \"HARM_SEVERITY_HIGH\",\n          \"severity_score\": 0.755637\n        }\n      ],\n      \"avg_logprobs\": \"NaN\"\n    }\n  ],\n  \"usage_metadata\": {\n    \"prompt_token_count\": 2065,\n    \"total_token_count\": 2065\n  }\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m messages_to_predict \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Compute the predictions using the zero-shot prompt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m predictions_tuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages_to_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuned_gemini_pro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 80\u001b[0m, in \u001b[0;36mbatch_predict\u001b[0;34m(messages, model, max_workers)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     79\u001b[0m     partial_func \u001b[38;5;241m=\u001b[39m partial(_predict_message, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m---> 80\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m, in \u001b[0;36mhandle_exception_threading.<locals>.applicator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mlog_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mlog_error\u001b[0;34m(msg, *args)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mLogs an error message and raises an exception.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    *args: Additional arguments to be passed to the logger.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m mp\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39merror(msg, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg)\n",
      "\u001b[0;31mException\u001b[0m: Traceback (most recent call last):\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1976, in text\n    return self.content.text\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 2055, in text\n    raise ValueError(\nValueError: Response candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1890, in text\n    return self.candidates[0].text\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1980, in text\n    raise ValueError(\nValueError: Cannot get the Candidate text.\nResponse candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\nCandidate:\n{\n  \"finish_reason\": \"SAFETY\",\n  \"safety_ratings\": [\n    {\n      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.21783626,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21601154\n    },\n    {\n      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.2757144,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21502088\n    },\n    {\n      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.23126681,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21255875\n    },\n    {\n      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n      \"probability\": \"HIGH\",\n      \"blocked\": true,\n      \"probability_score\": 0.9150529,\n      \"severity\": \"HARM_SEVERITY_HIGH\",\n      \"severity_score\": 0.755637\n    }\n  ],\n  \"avg_logprobs\": \"NaN\"\n}\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/tmp/ipykernel_196284/750188219.py\", line 36, in applicator\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/backoff/_sync.py\", line 105, in retry\n    ret = target(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/tmp/ipykernel_196284/750188219.py\", line 59, in _predict_message\n    return response.text\n           ^^^^^^^^^^^^^\n  File \"/home/sridhanya_ganapathi_team_neustar/.local/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py\", line 1894, in text\n    raise ValueError(\nValueError: Cannot get the response text.\nCannot get the Candidate text.\nResponse candidate content has no parts (and thus no text). The candidate is likely blocked by the safety filters.\nContent:\n{}\nCandidate:\n{\n  \"finish_reason\": \"SAFETY\",\n  \"safety_ratings\": [\n    {\n      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.21783626,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21601154\n    },\n    {\n      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.2757144,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21502088\n    },\n    {\n      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n      \"probability\": \"NEGLIGIBLE\",\n      \"probability_score\": 0.23126681,\n      \"severity\": \"HARM_SEVERITY_LOW\",\n      \"severity_score\": 0.21255875\n    },\n    {\n      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n      \"probability\": \"HIGH\",\n      \"blocked\": true,\n      \"probability_score\": 0.9150529,\n      \"severity\": \"HARM_SEVERITY_HIGH\",\n      \"severity_score\": 0.755637\n    }\n  ],\n  \"avg_logprobs\": \"NaN\"\n}\nResponse:\n{\n  \"candidates\": [\n    {\n      \"finish_reason\": \"SAFETY\",\n      \"safety_ratings\": [\n        {\n          \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.21783626,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21601154\n        },\n        {\n          \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.2757144,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21502088\n        },\n        {\n          \"category\": \"HARM_CATEGORY_HARASSMENT\",\n          \"probability\": \"NEGLIGIBLE\",\n          \"probability_score\": 0.23126681,\n          \"severity\": \"HARM_SEVERITY_LOW\",\n          \"severity_score\": 0.21255875\n        },\n        {\n          \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n          \"probability\": \"HIGH\",\n          \"blocked\": true,\n          \"probability_score\": 0.9150529,\n          \"severity\": \"HARM_SEVERITY_HIGH\",\n          \"severity_score\": 0.755637\n        }\n      ],\n      \"avg_logprobs\": \"NaN\"\n    }\n  ],\n  \"usage_metadata\": {\n    \"prompt_token_count\": 2065,\n    \"total_token_count\": 2065\n  }\n}\n"
     ]
    }
   ],
   "source": [
    "# Get the list of messages to predict\n",
    "messages_to_predict = test[\"Text\"].to_list()\n",
    "# Compute the predictions using the zero-shot prompt\n",
    "predictions_tuned_model = batch_predict(\n",
    "    messages=messages_to_predict, model=tuned_gemini_pro, max_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0d2d8d36-d38e-4cf1-bed5-a001f6265a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:04<00:00,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the list of messages to predict\n",
    "messages_to_predict = val[\"Text\"][0:25].to_list()\n",
    "# Compute the predictions using the zero-shot prompt\n",
    "predictions_tuned_model = batch_predict(\n",
    "    messages=messages_to_predict, model=tuned_gemini_pro, max_workers=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbeaf081-c5e1-461e-a9f7-35a1ffcf99f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tuned-gem1.0-ep4-lrm1-rank4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tuned-gem1.0-ep4-lrm1-rank4'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_evals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtuned-gem1.0-ep4-lrm1-rank4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tuned-gem1.0-ep4-lrm1-rank4'"
     ]
    }
   ],
   "source": [
    "df_evals[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ca17f-f120-4a8c-b9a2-0b2b2a4ea5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_tuned_gemini = evaluate_predictions(\n",
    "    df_evals.copy(),\n",
    "    target_column=\"label_text\",\n",
    "    predictions_column=\"tuned-gem1.0-ep4-lrm1-rank4\",\n",
    "    postprocessing=True,\n",
    ")\n",
    "metrics_tuned_gemini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
